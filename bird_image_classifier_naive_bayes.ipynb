{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # math library\n",
    "import pandas as pd # dataframe library\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # graphing library that builds ontop of mathplot\n",
    "import tensorflow as tf # machine learning library\n",
    "from tensorflow import keras # computer vision library from tensorflow \n",
    "import math\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "*Note: This is using a 5 class subset. The subset bird species are RUFOUS TREPE, HOUSE FINCH, D-ARNAUDS BARBET, OVENBIRD, ASIAN GREEN BEE EATER.\n",
    "These 5 were choosen because they had the most available data out of the 500+ species in the orginial dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training subset = RUFOUS TREPE, HOUSE FINCH, D-ARNAUDS BARBET, OVENBIRD, ASIAN GREEN BEE EATER\n",
    "#csv format: class id,filepaths(relative),labels,data set(e.g. training,valid or test),scientific name\n",
    "data = pd.read_csv(\"birds.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Exploratory Data Analysis (EDA)\n",
    "Worry about the EDA stuff after you get Naive Bayes working, it seems to matter little to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by data set and plotting histograms for each feature/label\n",
    "for dataset, subset in data.groupby('data set'):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    subset['labels'].hist(alpha=0.5, label=dataset)\n",
    "    plt.title(f'Histogram for data set: {dataset}')\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Implementation\n",
    "Features = Pixel\n",
    "P(Y=y), Y is the the target and is the precent chance of the target appearing. E.g. P(y) = 20%, if there are 20 out 100 sparrows in the data set of birds.\n",
    "P(Feature_n | Y) = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Computer vision!\n",
    "# loop through dataframe and load image into computer vision\n",
    "# constant for # bins(color groups) can +/- to +/- acc \n",
    "# Factor determines factor of reduction on color channels, e.g. 255 possible values per channel / 8 = 32 possible values per channel\n",
    "# Factor is essetnially grouping similar colors together and controls how aggresive the grouping is.\n",
    "FACTOR = 8\n",
    "for index, row in data.iterrows():\n",
    "    # read data set column of the given row\n",
    "    dataset = row['data set']\n",
    "    # skip over non-training data(data hygiene protection) to avoid trainning on valid/test data\n",
    "    if dataset != 'train':\n",
    "        continue\n",
    "    # read filepath col of the given row\n",
    "    filepath = row['filepaths']\n",
    "    # read label\n",
    "    label = row['labels']\n",
    "    # load image into computer vision using native image size(this data set has an universal image size)\n",
    "    image = tf.keras.utils.load_img(filepath)\n",
    "    # the image is 224x224x3 (width x height x color_channels)\n",
    "    image_array = tf.keras.utils.img_to_array(image,data_format='channels_last')\n",
    "    \n",
    "    # group similar colors together to reduce computation time based on a constant value that can be adjusted\n",
    "    image_array = image_array // FACTOR # Reduce from 255x255x255 to 32x32x32, much easier for bayes\n",
    "    # create enough color bins for each grouped color dynimcally.\n",
    "    bins_num = math.ceil(255 / FACTOR)\n",
    "    \n",
    "    # 3D Slice colstart:colstop, rowstart:rowstop, depthstart:depthstop\n",
    "    # Splitting the image_array into R, G, B channels\n",
    "    red_channel = image_array[:, :, 0]\n",
    "    green_channel = image_array[:, :, 1]\n",
    "    blue_channel = image_array[:, :, 2]\n",
    "    \n",
    "    # Create histograms data strucutre for each channel group (255 // 8 = 32)\n",
    "    # x_hist = array, x_bins = bins start indexes in said array\n",
    "    # note, since each color group has it's own bin, each index i corresponds to bin i making x_bins variable redundant.\n",
    "    red_hist, red_bins = np.histogram(red_channel, bins=bins_num, range=(0, bins_num))\n",
    "    green_hist, green_bins = np.histogram(green_channel, bins=bins_num, range=(0, bins_num))\n",
    "    blue_hist, blue_bins = np.histogram(blue_channel, bins=bins_num, range=(0, bins_num))\n",
    "    \n",
    "    # Plotting histograms for each channel\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.hist(red_channel.flatten(), bins=bins_num, range=(0, bins_num), color='red', alpha=0.5, label='Red')\n",
    "    plt.hist(green_channel.flatten(), bins=bins_num, range=(0, bins_num), color='green', alpha=0.5, label='Green')\n",
    "    plt.hist(blue_channel.flatten(), bins=bins_num, range=(0, bins_num), color='blue', alpha=0.5, label='Blue')\n",
    "\n",
    "    plt.xlabel('Pixel Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Pixel Color Values (R, G, B)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #TODO: Remove this break!\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Function\n",
    "Function should be implemented in the block above. See planning doc for how to assign prob values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in the pixel color channel histograms derived from a given image\n",
    "# take in target, feature name,\n",
    "def Naive_Bayes(redHisto,greenHisto,blueHisto):\n",
    "    # all data set images are in 224 * 224\n",
    "    TOTAL_PIXELS = 224 * 224\n",
    "    #P(Feature) = pixels in bin / total pixels(224x224)\n",
    "    #P(Y) = # Y bird in data set / # total birds in dataset(need to check / dynamically cal earlier)\n",
    "    #P(Feature | Y) = (Occurrences of color_bin(Feature) in images of Y) / (Total pixel occurrences in histograms of Y) \n",
    "    # The above requires some running sums.\n",
    "    # Those are the 3 probs needed for naive bayes\n",
    "    # Need to consider partial \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder for now. Seems like sklearn.metrics is what we are meant to be use. Which means sklearn intergration somewhat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=.2, random_state=41)\n",
    "\n",
    "X_test = test.iloc[:,:-1].values # test features\n",
    "Y_test = test.iloc[:,-1].values # test labels\n",
    "Y_pred = naive_bayes_categorical(train, X=X_test, Y=\"diagnosis\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
